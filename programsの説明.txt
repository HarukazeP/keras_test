-----ForCourpusディレクトリ内----------------------------------------

FilePro5.java　と　WikiSentCheck.java
以前に作成したもの．wp2txtで得たWikipediaの記事データを整形するやつ


make_dic.py
単語一覧をファイル出力する
学習データのコーパスが大きいとき，1行ずつ読み込む必要があるが，単語のid辞書は先に作成する必要があったため


process_wiki.py
Wikipediaの記事コーパスを作成
http://tatzyr.hatenablog.com/entry/2015/10/24/162102　このサイトにあったものだが今は記事消えてる


-----2017_from04to07ディレクトリ内----------------------------------------

original.py
kerasのチュートリアルプログラムlstm_text_generation.py　そのまま
https://github.com/fchollet/keras/tree/master/examples　より


original_time.py
original.py　に時間表示を追加


-------これより下「char」で始まるものは文字ベースで予測するモデル．「word」で始まるものは単語ベースで予測するモデル
-------「test」がつくものはチュートリアルと同じ学習・テストデータ

sampling_test.py
original_time.py　に簡単な前処理追加（改行をスペースに，スペースの連続を消す），繰り返し回数減らして軽量化
サンプリングが何をやっているのか確認用


char_sampling2_test.py
サンプリングで複数出力できるように変更，学習データも減らして軽量化


word_test.py
文字ベースから単語ベースへ．さらに前処理を追加．（a～zのみに）
文字ベース時の変数sentenceと単語ベース時の変数sentenceは型が違うことに注意


char_word_test.py
char_sampling2_test.py　に前処理を追加．（a～zのみに）
文字べースで予測し，スペースが出るまでを1単語として出力


char_merge_old_test.py
順方向と逆方向から予測してマージする．
Mergeメソッドを用いているが，このMergeは2017/8以降使えなくなるらしい


char_merge_new_test.py
char_merge_old_test.py　をMergeからfunctionAPIを用いた方法に変えたもの


word_merge_new_test.py
char_merge_new_test.py　の単語ベースver



word_merge_new_wiki_once.py　
※不完全なプログラム
word_merge_new_test.py　の学習データをwikiに変えたもの．iterationループをなくした
モデルを保存する機能追加
これではデータが大きすぎて(約6.3GB)動かなかった


word_miniWiki.py
word_merge_new_wiki_once.py　から学習データ変えただけ
学習データn行おきに1行抽出して約1.5MBに


word_wiki_line.py
※不完全なプログラム
word_miniWiki.py　から学習データが大きい場合に備えて1行ずつ学習していく
AttributeError:'Progbar Logger' object has no attribute 'log_values'　みたいなエラーが出てうごかない


word_wiki_not_line.py
word_miniWiki.py　から辞書にその他を表す#OTHERを追加
出力ファイル名に日付を付与


word_save_model_goudouzemi2.py
合同ゼミ用
word_wiki_not_line.py　から出力とか微妙に変更


word_load_model_goudouzemi2.py
合同ゼミ用
保存してあるモデルを使用して予測
これは実行にそんなに時間かからない


calc_rank_ans.py
合同ゼミ実験1用
word_load_model_goudouzemi2.py　が出力したファイルや正解データから正解率を計算


calc_preds_ans.py
合同ゼミ実験2用
word_load_model_goudouzemi2.py　が出力したファイルや正解データから正解率を計算


calc_preds_to_rank.py
合同ゼミ実験2用
word_load_model_goudouzemi2.py　が出力したファイルや正解データから予測の確率順位を出力




-----2017_from08to11ディレクトリ内----------------------------------------

word_all_after_goudouzemi.py
合同ゼミ用のプログラムでは学習→テスト→正誤判定が分かれていたり，手動部分があったりしたが，それらを一体化し完全自動化
正解付きテストデータと選択肢つきテストデータを読み込む


word_onehot.py
word_all_after_goudouzemi.py　とほど同じ
学習回数(epoch)などを変更して実験する

word_embedding.py
word_onehot.py　からベクトル化をonehotではなくembedding用いたものへ変更
文字列→単語id+1→embeddingの流れ







